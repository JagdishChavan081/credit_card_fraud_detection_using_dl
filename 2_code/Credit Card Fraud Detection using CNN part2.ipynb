{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "#importing dataset\n",
    "dataset = pd.read_csv('/home/jagdish/pytn/7_projects/credit/3_dset/dataset.csv')\n",
    "\n",
    "#split in input and output\n",
    "#matrix of features\n",
    "x = dataset.drop(labels=['Class'], axis=1)\n",
    "#dependent variable\n",
    "y = dataset['Class']\n",
    "\n",
    "#spliing data into train test split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "#reshaping the dataset\n",
    "x_train=x_train.reshape(787, 30, 1 )\n",
    "x_test=x_test.reshape(197, 30, 1)\n",
    "\n",
    "#define model\n",
    "model = tf.keras.models.Sequential()\n",
    "#first CNN layer\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=2, padding='same',activation='relu',input_shape=(30,1)))\n",
    "#batch normalization \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#maxpool layer\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=2))\n",
    "#droupout layer\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "# Second CNN layer\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, padding='same',activation='relu',input_shape=(30,1)))\n",
    "#batch normalization \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#maxpool layer\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=2))\n",
    "#droupout layer\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "#flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "#first dense layer\n",
    "model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "#droupout layer\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "#outputlayer\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(x_train,y_train, epochs=25, batch_size=32,verbose=0)\n",
    "\n",
    "\n",
    "# save model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "# example of loading a saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "# create the dataset\n",
    "\n",
    "# load the model from file\n",
    "model = load_model('model.h5')\n",
    "# make a prediction\n",
    "row = [115655,2.0624638031039,0.053613772019551,-2.06017481536173,0.106916296444245,0.908747838864355,-0.043866972343101,0.105116122060478,-0.054179574695209,0.248445497863778,-0.224087525344249,0.399433594439311,0.701617778206057,0.424728765654036,-0.754089262989451,-0.461086896946629,0.756059151204773,-0.110746539009176,0.440403558762576,0.664367500177951,-0.065001618542861,-0.357174513099665,-0.977868376227852,0.201649348502882,-0.383597800160371,-0.167858541755907,0.205641140586159,-0.068834863995798,-0.046037966553021,17.99\n",
    "]\n",
    "\n",
    "row=pd.Series(row)\n",
    "# convert series object into array\n",
    "arr = row.values\n",
    "# reshaping series \n",
    "reshaped_arr = arr.reshape((1, 30,1))\n",
    "\n",
    "\n",
    "yhat = model.predict(reshaped_arr)\n",
    "print('Predicted: %.f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}